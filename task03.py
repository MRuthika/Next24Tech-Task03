# -*- coding: utf-8 -*-
"""Task03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q4Zp1VBiEZiS_JC2to6IiFL1faoU45he

**Data Preprocessing**
"""

import pandas as pd
import re
import string

# Load the dataset
try:
    data = pd.read_csv('/content/IMDB Dataset.csv')
    print("Data loaded successfully.")
except FileNotFoundError:
    print("File not found. Please make sure the dataset is in the correct path.")
except Exception as e:
    print(f"Error loading data: {e}")

# Preview the dataset
print("Data Preview:")
print(data.head())

# Function to clean the text
def clean_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'http\S+', '', text)  # Remove URLs
    text = re.sub(r'@\w+', '', text)  # Remove mentions
    text = re.sub(r'#\w+', '', text)  # Remove hashtags
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    return text

# Apply the cleaning function to the text data
try:
    data['clean_text'] = data['review'].apply(clean_text)
    print("Text cleaning completed successfully.")
except Exception as e:
    print(f"Error during text cleaning: {e}")

# Preview cleaned data
print("Cleaned Data Preview:")
print(data[['review', 'clean_text']].head())

"""**Feature Extraction**"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Feature Extraction using TF-IDF
try:
    tfidf = TfidfVectorizer(max_features=5000)
    X = tfidf.fit_transform(data['clean_text']).toarray()
    y = data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)  # Convert sentiments to 1 and 0
    print("Feature extraction completed successfully.")
except Exception as e:
    print(f"Error during feature extraction: {e}")

# Print shape of features and labels
print("Features Shape:", X.shape)
print("Labels Shape:", y.shape)

"""**Model Selection and Training**"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Split the data into training and testing sets
try:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    print("Data splitting completed successfully.")
except Exception as e:
    print(f"Error during data splitting: {e}")

# Initialize and train the Logistic Regression model
try:
    model = LogisticRegression(max_iter=200)
    model.fit(X_train, y_train)
    print("Model training completed successfully.")
except Exception as e:
    print(f"Error during model training: {e}")

# Predict sentiments on the test set
try:
    y_pred = model.predict(X_test)
    print("Model prediction completed successfully.")
except Exception as e:
    print(f"Error during model prediction: {e}")

"""**Model Evaluation**"""

import seaborn as sns
import matplotlib.pyplot as plt

# Classification report
try:
    print("Classification Report:")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:")
    cm = confusion_matrix(y_test, y_pred)
    print(cm)
    print("Accuracy Score:", accuracy_score(y_test, y_pred))
except Exception as e:
    print(f"Error during model evaluation: {e}")

# Confusion Matrix Visualization
try:
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.show()
except Exception as e:
    print(f"Error during confusion matrix visualization: {e}")